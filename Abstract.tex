\textit{Is there a way do high-quality seismic interpolation fast and cheap?}  This thesis introduces a novel approach for translating low-to-high-quality seismic images using deep learning, employing three distinct models: Generative Adversarial Network (GAN), a modified Swin Transformer Convolutional Residual Network (SCRN) as developed by Gao et al. (2024), and their hybrid variant, the Swin Transformer Convolutional Residual Generative Adversarial Network (SCR-GAN). The model hyper-parameters are optimised through extensive analysis.
\\\\
The two-step workflow is as follows: 1) Train the neural network model with paired images: standard-resolution images obtained from low-cost processing and high-quality images from high-cost processing. 2) Input the unseen low-cost standard-resolution datasets into the trained model to transform them into high-resolution counterparts. This workflow is pioneering in producing high-resolution output from a low-resolution processing sequence in an end-to-end manner while mitigating the computational bottleneck of high-resolution technology.
\\\\ 
To demonstrate the feasibility of translating low-to-high-quality seismic images with deep learning, we used interpolation as an example. Matching Pursuit Fourier Interpolation (MPFI) and Time Domain Radon Interpolation (TDRI) are commonly used interpolators in the industry. TDRI, which applies basis functions in a higher-dimensional tau-p domain, provides higher accuracy but at a significantly higher computational cost—127,294 CPU hours to process 3700 km² areal data, compared to 13 CPU hours with MPFI. Our focus is on translating MPFI images (standard quality) to pseudo-TDRI images (state-of-the-art quality) using the two-step workflow. The resemblance between the deep-learning-generated pseudo-TDRI images and ground truth is assessed quantitatively and qualitatively to identify the best model. GAN, SCRN, and SCR-GAN achieve SNR values of 15.19 dB, 16.32 dB, and 16.25 dB, respectively, on reconstructions using unseen datasets. SCRN outperforms the others in terms of image resemblance and de-noising capability, even exceeding TDRI. Training SCRN requires 23.42 GPU hours, with translation taking just 11 GPU minutes. Once the model is trained, translating MPFI to TDRI quality requires less than 14 CPU hours, which is nearly four orders of magnitude faster than the traditional TDRI process.
\\\\
Keyword: Seismic interpolation, image-to-image translation, generative adversarial networks (GANs), vision transformer (ViT), Swin transformer
